{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f35f14-3e51-4bae-8951-b4051f38e788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diagnostic_msgs.msg import DiagnosticArray, DiagnosticStatus, KeyValue\n",
    "from foxglove_msgs.msg import ImageMarkerArray\n",
    "from geometry_msgs.msg import Point, Pose, PoseStamped, Transform, TransformStamped\n",
    "from matplotlib import pyplot as plt\n",
    "from nav_msgs.msg import OccupancyGrid, Odometry\n",
    "from nuscenes.can_bus.can_bus_api import NuScenesCanBus\n",
    "from nuscenes.eval.common.utils import quaternion_yaw\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from pprint import pprint\n",
    "from pypcd import numpy_pc2, pypcd\n",
    "from pyquaternion import Quaternion\n",
    "from sensor_msgs.msg import CameraInfo, CompressedImage, Imu, NavSatFix, PointCloud2, PointField\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "from std_msgs.msg import ColorRGBA\n",
    "from tf2_msgs.msg import TFMessage\n",
    "from typing import List, Tuple, Dict\n",
    "from visualization_msgs.msg import ImageMarker, Marker, MarkerArray\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import rosbag\n",
    "import rospy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitMap:\n",
    "\n",
    "    def __init__(self, dataroot: str, map_name: str, layer_name: str):\n",
    "        \"\"\"\n",
    "        This class is used to render bitmap map layers. Currently these are:\n",
    "        - semantic_prior: The semantic prior (driveable surface and sidewalks) mask from nuScenes 1.0.\n",
    "        - basemap: The HD lidar basemap used for localization and as general context.\n",
    "\n",
    "        :param dataroot: Path of the nuScenes dataset.\n",
    "        :param map_name: Which map out of `singapore-onenorth`, `singepore-hollandvillage`, `singapore-queenstown` and\n",
    "            'boston-seaport'.\n",
    "        :param layer_name: The type of bitmap map, `semanitc_prior` or `basemap.\n",
    "        \"\"\"\n",
    "        self.dataroot = dataroot\n",
    "        self.map_name = map_name\n",
    "        self.layer_name = layer_name\n",
    "\n",
    "        self.image = self.load_bitmap()\n",
    "\n",
    "    def load_bitmap(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Load the specified bitmap.\n",
    "        \"\"\"\n",
    "        # Load bitmap.\n",
    "        if self.layer_name == 'basemap':\n",
    "            map_path = os.path.join(self.dataroot, 'maps', 'basemap', self.map_name + '.png')\n",
    "        elif self.layer_name == 'semantic_prior':\n",
    "            map_hashes = {\n",
    "                'singapore-onenorth': '53992ee3023e5494b90c316c183be829',\n",
    "                'singapore-hollandvillage': '37819e65e09e5547b8a3ceaefba56bb2',\n",
    "                'singapore-queenstown': '93406b464a165eaba6d9de76ca09f5da',\n",
    "                'boston-seaport': '36092f0b03a857c6a3403e25b4b7aab3'\n",
    "            }\n",
    "            map_hash = map_hashes[self.map_name]\n",
    "            map_path = os.path.join(self.dataroot, 'maps', map_hash + '.png')\n",
    "        else:\n",
    "            raise Exception('Error: Invalid bitmap layer: %s' % self.layer_name)\n",
    "\n",
    "        # Convert to numpy.\n",
    "        if os.path.exists(map_path):\n",
    "            image = np.array(Image.open(map_path).convert('L'))\n",
    "        else:\n",
    "            raise Exception('Error: Cannot find %s %s! Please make sure that the map is correctly installed.'\n",
    "                            % (self.layer_name, map_path))\n",
    "\n",
    "        # Invert semantic prior colors.\n",
    "        if self.layer_name == 'semantic_prior':\n",
    "            image = image.max() - image\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756a013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUSCENES_VERSION = 'v1.0-mini'\n",
    "\n",
    "nusc = NuScenes(version=NUSCENES_VERSION, dataroot='data', verbose=True)\n",
    "nusc_can = NuScenesCanBus(dataroot='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbdf45-21a2-4738-97a2-4b80fa5b5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc.list_scenes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1391fef-09ff-40eb-af33-b2160cac72b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EARTH_RADIUS_METERS = 6.378137e6\n",
    "REFERENCE_COORDINATES = {\n",
    "    \"boston-seaport\": [42.336849169438615, -71.05785369873047],\n",
    "    \"singapore-onenorth\": [1.2882100868743724, 103.78475189208984],\n",
    "    \"singapore-hollandvillage\": [1.2993652317780957, 103.78217697143555],\n",
    "    \"singapore-queenstown\": [1.2782562240223188, 103.76741409301758],\n",
    "}\n",
    "\n",
    "def get_coordinate(ref_lat: float, ref_lon: float, bearing: float, dist: float) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Using a reference coordinate, extract the coordinates of another point in space given its distance and bearing\n",
    "    to the reference coordinate. For reference, please see: https://www.movable-type.co.uk/scripts/latlong.html.\n",
    "    :param ref_lat: Latitude of the reference coordinate in degrees, ie: 42.3368.\n",
    "    :param ref_lon: Longitude of the reference coordinate in degrees, ie: 71.0578.\n",
    "    :param bearing: The clockwise angle in radians between target point, reference point and the axis pointing north.\n",
    "    :param dist: The distance in meters from the reference point to the target point.\n",
    "    :return: A tuple of lat and lon.\n",
    "    \"\"\"\n",
    "    lat, lon = math.radians(ref_lat), math.radians(ref_lon)\n",
    "    angular_distance = dist / EARTH_RADIUS_METERS\n",
    "\n",
    "    target_lat = math.asin(\n",
    "        math.sin(lat) * math.cos(angular_distance) + \n",
    "        math.cos(lat) * math.sin(angular_distance) * math.cos(bearing)\n",
    "    )\n",
    "    target_lon = lon + math.atan2(\n",
    "        math.sin(bearing) * math.sin(angular_distance) * math.cos(lat),\n",
    "        math.cos(angular_distance) - math.sin(lat) * math.sin(target_lat)\n",
    "    )\n",
    "    return math.degrees(target_lat), math.degrees(target_lon)\n",
    "\n",
    "def derive_latlon(location: str, pose: Dict[str, float]):\n",
    "    \"\"\"\n",
    "    For each pose value, extract its respective lat/lon coordinate and timestamp.\n",
    "    \n",
    "    This makes the following two assumptions in order to work:\n",
    "        1. The reference coordinate for each map is in the south-western corner.\n",
    "        2. The origin of the global poses is also in the south-western corner (and identical to 1).\n",
    "    :param location: The name of the map the poses correspond to, ie: 'boston-seaport'.\n",
    "    :param poses: All nuScenes egopose dictionaries of a scene.\n",
    "    :return: A list of dicts (lat/lon coordinates and timestamps) for each pose.\n",
    "    \"\"\"\n",
    "    assert location in REFERENCE_COORDINATES.keys(), \\\n",
    "        f'Error: The given location: {location}, has no available reference.'\n",
    "\n",
    "    coordinates = []\n",
    "    reference_lat, reference_lon = REFERENCE_COORDINATES[location]\n",
    "    ts = pose['timestamp']\n",
    "    x, y = pose['translation'][:2]\n",
    "    bearing = math.atan(x / y)\n",
    "    distance = math.sqrt(x**2 + y**2)\n",
    "    lat, lon = get_coordinate(reference_lat, reference_lon, bearing, distance)\n",
    "    return {'latitude': lat, 'longitude': lon}\n",
    "\n",
    "def get_transform(data):\n",
    "    t = Transform()\n",
    "    t.translation.x = data['translation'][0]\n",
    "    t.translation.y = data['translation'][1]\n",
    "    t.translation.z = data['translation'][2]\n",
    "    \n",
    "    t.rotation.w = data['rotation'][0]\n",
    "    t.rotation.x = data['rotation'][1]\n",
    "    t.rotation.y = data['rotation'][2]\n",
    "    t.rotation.z = data['rotation'][3]\n",
    "    \n",
    "    return t\n",
    "\n",
    "def get_pose(data):\n",
    "    p = Pose()\n",
    "    p.position.x = data['translation'][0]\n",
    "    p.position.y = data['translation'][1]\n",
    "    p.position.z = data['translation'][2]\n",
    "    \n",
    "    p.orientation.w = data['rotation'][0]\n",
    "    p.orientation.x = data['rotation'][1]\n",
    "    p.orientation.y = data['rotation'][2]\n",
    "    p.orientation.z = data['rotation'][3]\n",
    "    \n",
    "    return p\n",
    "\n",
    "def get_time(data):\n",
    "    t = rospy.Time()\n",
    "    t.secs, msecs = divmod(data['timestamp'], 1_000_000)\n",
    "    t.nsecs = msecs * 1000\n",
    "\n",
    "    return t\n",
    "\n",
    "def get_utime(data):\n",
    "    t = rospy.Time()\n",
    "    t.secs, msecs = divmod(data['utime'], 1_000_000)\n",
    "    t.nsecs = msecs * 1000\n",
    "\n",
    "    return t\n",
    "\n",
    "def make_point(xyz):\n",
    "    p = Point()\n",
    "    p.x = xyz[0]\n",
    "    p.y = xyz[1]\n",
    "    p.z = xyz[2]\n",
    "    return p\n",
    "\n",
    "def make_point2d(xy):\n",
    "    p = Point()\n",
    "    p.x = xy[0]\n",
    "    p.y = xy[1]\n",
    "    p.z = 0.0\n",
    "    return p\n",
    "\n",
    "def make_color(rgb, a=1):\n",
    "    c = ColorRGBA()\n",
    "    c.r = rgb[0]\n",
    "    c.g = rgb[1]\n",
    "    c.b = rgb[2]\n",
    "    c.a = a\n",
    "    \n",
    "    return c\n",
    "\n",
    "turbo_colormap_data = [[0.18995,0.07176,0.23217],[0.19483,0.08339,0.26149],[0.19956,0.09498,0.29024],[0.20415,0.10652,0.31844],[0.20860,0.11802,0.34607],[0.21291,0.12947,0.37314],[0.21708,0.14087,0.39964],[0.22111,0.15223,0.42558],[0.22500,0.16354,0.45096],[0.22875,0.17481,0.47578],[0.23236,0.18603,0.50004],[0.23582,0.19720,0.52373],[0.23915,0.20833,0.54686],[0.24234,0.21941,0.56942],[0.24539,0.23044,0.59142],[0.24830,0.24143,0.61286],[0.25107,0.25237,0.63374],[0.25369,0.26327,0.65406],[0.25618,0.27412,0.67381],[0.25853,0.28492,0.69300],[0.26074,0.29568,0.71162],[0.26280,0.30639,0.72968],[0.26473,0.31706,0.74718],[0.26652,0.32768,0.76412],[0.26816,0.33825,0.78050],[0.26967,0.34878,0.79631],[0.27103,0.35926,0.81156],[0.27226,0.36970,0.82624],[0.27334,0.38008,0.84037],[0.27429,0.39043,0.85393],[0.27509,0.40072,0.86692],[0.27576,0.41097,0.87936],[0.27628,0.42118,0.89123],[0.27667,0.43134,0.90254],[0.27691,0.44145,0.91328],[0.27701,0.45152,0.92347],[0.27698,0.46153,0.93309],[0.27680,0.47151,0.94214],[0.27648,0.48144,0.95064],[0.27603,0.49132,0.95857],[0.27543,0.50115,0.96594],[0.27469,0.51094,0.97275],[0.27381,0.52069,0.97899],[0.27273,0.53040,0.98461],[0.27106,0.54015,0.98930],[0.26878,0.54995,0.99303],[0.26592,0.55979,0.99583],[0.26252,0.56967,0.99773],[0.25862,0.57958,0.99876],[0.25425,0.58950,0.99896],[0.24946,0.59943,0.99835],[0.24427,0.60937,0.99697],[0.23874,0.61931,0.99485],[0.23288,0.62923,0.99202],[0.22676,0.63913,0.98851],[0.22039,0.64901,0.98436],[0.21382,0.65886,0.97959],[0.20708,0.66866,0.97423],[0.20021,0.67842,0.96833],[0.19326,0.68812,0.96190],[0.18625,0.69775,0.95498],[0.17923,0.70732,0.94761],[0.17223,0.71680,0.93981],[0.16529,0.72620,0.93161],[0.15844,0.73551,0.92305],[0.15173,0.74472,0.91416],[0.14519,0.75381,0.90496],[0.13886,0.76279,0.89550],[0.13278,0.77165,0.88580],[0.12698,0.78037,0.87590],[0.12151,0.78896,0.86581],[0.11639,0.79740,0.85559],[0.11167,0.80569,0.84525],[0.10738,0.81381,0.83484],[0.10357,0.82177,0.82437],[0.10026,0.82955,0.81389],[0.09750,0.83714,0.80342],[0.09532,0.84455,0.79299],[0.09377,0.85175,0.78264],[0.09287,0.85875,0.77240],[0.09267,0.86554,0.76230],[0.09320,0.87211,0.75237],[0.09451,0.87844,0.74265],[0.09662,0.88454,0.73316],[0.09958,0.89040,0.72393],[0.10342,0.89600,0.71500],[0.10815,0.90142,0.70599],[0.11374,0.90673,0.69651],[0.12014,0.91193,0.68660],[0.12733,0.91701,0.67627],[0.13526,0.92197,0.66556],[0.14391,0.92680,0.65448],[0.15323,0.93151,0.64308],[0.16319,0.93609,0.63137],[0.17377,0.94053,0.61938],[0.18491,0.94484,0.60713],[0.19659,0.94901,0.59466],[0.20877,0.95304,0.58199],[0.22142,0.95692,0.56914],[0.23449,0.96065,0.55614],[0.24797,0.96423,0.54303],[0.26180,0.96765,0.52981],[0.27597,0.97092,0.51653],[0.29042,0.97403,0.50321],[0.30513,0.97697,0.48987],[0.32006,0.97974,0.47654],[0.33517,0.98234,0.46325],[0.35043,0.98477,0.45002],[0.36581,0.98702,0.43688],[0.38127,0.98909,0.42386],[0.39678,0.99098,0.41098],[0.41229,0.99268,0.39826],[0.42778,0.99419,0.38575],[0.44321,0.99551,0.37345],[0.45854,0.99663,0.36140],[0.47375,0.99755,0.34963],[0.48879,0.99828,0.33816],[0.50362,0.99879,0.32701],[0.51822,0.99910,0.31622],[0.53255,0.99919,0.30581],[0.54658,0.99907,0.29581],[0.56026,0.99873,0.28623],[0.57357,0.99817,0.27712],[0.58646,0.99739,0.26849],[0.59891,0.99638,0.26038],[0.61088,0.99514,0.25280],[0.62233,0.99366,0.24579],[0.63323,0.99195,0.23937],[0.64362,0.98999,0.23356],[0.65394,0.98775,0.22835],[0.66428,0.98524,0.22370],[0.67462,0.98246,0.21960],[0.68494,0.97941,0.21602],[0.69525,0.97610,0.21294],[0.70553,0.97255,0.21032],[0.71577,0.96875,0.20815],[0.72596,0.96470,0.20640],[0.73610,0.96043,0.20504],[0.74617,0.95593,0.20406],[0.75617,0.95121,0.20343],[0.76608,0.94627,0.20311],[0.77591,0.94113,0.20310],[0.78563,0.93579,0.20336],[0.79524,0.93025,0.20386],[0.80473,0.92452,0.20459],[0.81410,0.91861,0.20552],[0.82333,0.91253,0.20663],[0.83241,0.90627,0.20788],[0.84133,0.89986,0.20926],[0.85010,0.89328,0.21074],[0.85868,0.88655,0.21230],[0.86709,0.87968,0.21391],[0.87530,0.87267,0.21555],[0.88331,0.86553,0.21719],[0.89112,0.85826,0.21880],[0.89870,0.85087,0.22038],[0.90605,0.84337,0.22188],[0.91317,0.83576,0.22328],[0.92004,0.82806,0.22456],[0.92666,0.82025,0.22570],[0.93301,0.81236,0.22667],[0.93909,0.80439,0.22744],[0.94489,0.79634,0.22800],[0.95039,0.78823,0.22831],[0.95560,0.78005,0.22836],[0.96049,0.77181,0.22811],[0.96507,0.76352,0.22754],[0.96931,0.75519,0.22663],[0.97323,0.74682,0.22536],[0.97679,0.73842,0.22369],[0.98000,0.73000,0.22161],[0.98289,0.72140,0.21918],[0.98549,0.71250,0.21650],[0.98781,0.70330,0.21358],[0.98986,0.69382,0.21043],[0.99163,0.68408,0.20706],[0.99314,0.67408,0.20348],[0.99438,0.66386,0.19971],[0.99535,0.65341,0.19577],[0.99607,0.64277,0.19165],[0.99654,0.63193,0.18738],[0.99675,0.62093,0.18297],[0.99672,0.60977,0.17842],[0.99644,0.59846,0.17376],[0.99593,0.58703,0.16899],[0.99517,0.57549,0.16412],[0.99419,0.56386,0.15918],[0.99297,0.55214,0.15417],[0.99153,0.54036,0.14910],[0.98987,0.52854,0.14398],[0.98799,0.51667,0.13883],[0.98590,0.50479,0.13367],[0.98360,0.49291,0.12849],[0.98108,0.48104,0.12332],[0.97837,0.46920,0.11817],[0.97545,0.45740,0.11305],[0.97234,0.44565,0.10797],[0.96904,0.43399,0.10294],[0.96555,0.42241,0.09798],[0.96187,0.41093,0.09310],[0.95801,0.39958,0.08831],[0.95398,0.38836,0.08362],[0.94977,0.37729,0.07905],[0.94538,0.36638,0.07461],[0.94084,0.35566,0.07031],[0.93612,0.34513,0.06616],[0.93125,0.33482,0.06218],[0.92623,0.32473,0.05837],[0.92105,0.31489,0.05475],[0.91572,0.30530,0.05134],[0.91024,0.29599,0.04814],[0.90463,0.28696,0.04516],[0.89888,0.27824,0.04243],[0.89298,0.26981,0.03993],[0.88691,0.26152,0.03753],[0.88066,0.25334,0.03521],[0.87422,0.24526,0.03297],[0.86760,0.23730,0.03082],[0.86079,0.22945,0.02875],[0.85380,0.22170,0.02677],[0.84662,0.21407,0.02487],[0.83926,0.20654,0.02305],[0.83172,0.19912,0.02131],[0.82399,0.19182,0.01966],[0.81608,0.18462,0.01809],[0.80799,0.17753,0.01660],[0.79971,0.17055,0.01520],[0.79125,0.16368,0.01387],[0.78260,0.15693,0.01264],[0.77377,0.15028,0.01148],[0.76476,0.14374,0.01041],[0.75556,0.13731,0.00942],[0.74617,0.13098,0.00851],[0.73661,0.12477,0.00769],[0.72686,0.11867,0.00695],[0.71692,0.11268,0.00629],[0.70680,0.10680,0.00571],[0.69650,0.10102,0.00522],[0.68602,0.09536,0.00481],[0.67535,0.08980,0.00449],[0.66449,0.08436,0.00424],[0.65345,0.07902,0.00408],[0.64223,0.07380,0.00401],[0.63082,0.06868,0.00401],[0.61923,0.06367,0.00410],[0.60746,0.05878,0.00427],[0.59550,0.05399,0.00453],[0.58336,0.04931,0.00486],[0.57103,0.04474,0.00529],[0.55852,0.04028,0.00579],[0.54583,0.03593,0.00638],[0.53295,0.03169,0.00705],[0.51989,0.02756,0.00780],[0.50664,0.02354,0.00863],[0.49321,0.01963,0.00955],[0.47960,0.01583,0.01055]]\n",
    "\n",
    "def turbomap(x):\n",
    "  colormap = turbo_colormap_data\n",
    "  x = max(0.0, min(1.0, x))\n",
    "  a = int(x*255.0)\n",
    "  b = min(255, a + 1)\n",
    "  f = x*255.0 - a\n",
    "  return [colormap[a][0] + (colormap[b][0] - colormap[a][0]) * f,\n",
    "          colormap[a][1] + (colormap[b][1] - colormap[a][1]) * f,\n",
    "          colormap[a][2] + (colormap[b][2] - colormap[a][2]) * f]\n",
    "\n",
    "def get_categories(first_sample):\n",
    "    categories = set()\n",
    "    sample_lidar = first_sample\n",
    "    while sample_lidar is not None:\n",
    "        sample = nusc.get('sample', sample_lidar['sample_token'])\n",
    "        for annotation_id in sample['anns']:\n",
    "            ann = nusc.get('sample_annotation', annotation_id)\n",
    "            categories.add(ann['category_name'])\n",
    "        sample_lidar = nusc.get('sample_data', sample_lidar['next']) if sample_lidar.get('next') != '' else None\n",
    "    return categories\n",
    "\n",
    "def get_radar(sample_data, frame_id):\n",
    "    pc_filename = 'data/' + sample_data['filename']\n",
    "    pc = pypcd.PointCloud.from_path(pc_filename)\n",
    "    msg = numpy_pc2.array_to_pointcloud2(pc.pc_data)\n",
    "    msg.header.frame_id = frame_id\n",
    "    msg.header.stamp = get_time(sample_data)\n",
    "    return msg\n",
    "\n",
    "def get_camera(sample_data, frame_id):\n",
    "    jpg_filename = 'data/' + sample_data['filename']\n",
    "    msg = CompressedImage()\n",
    "    msg.header.frame_id = frame_id\n",
    "    msg.header.stamp = get_time(sample_data)\n",
    "    msg.format = \"jpeg\"\n",
    "    with open(jpg_filename, 'rb') as jpg_file:\n",
    "        msg.data = jpg_file.read()\n",
    "    return msg\n",
    "\n",
    "def get_camera_info(sample_data, frame_id):\n",
    "    calib = nusc.get('calibrated_sensor', sample_data['calibrated_sensor_token'])\n",
    "\n",
    "    msg_info = CameraInfo()\n",
    "    msg_info.header.frame_id = frame_id\n",
    "    msg_info.header.stamp = get_time(sample_data)\n",
    "    msg_info.height = sample_data['height']\n",
    "    msg_info.width = sample_data['width']\n",
    "    msg_info.K[0] = calib['camera_intrinsic'][0][0]\n",
    "    msg_info.K[1] = calib['camera_intrinsic'][0][1]\n",
    "    msg_info.K[2] = calib['camera_intrinsic'][0][2]\n",
    "    msg_info.K[3] = calib['camera_intrinsic'][1][0]\n",
    "    msg_info.K[4] = calib['camera_intrinsic'][1][1]\n",
    "    msg_info.K[5] = calib['camera_intrinsic'][1][2]\n",
    "    msg_info.K[6] = calib['camera_intrinsic'][2][0]\n",
    "    msg_info.K[7] = calib['camera_intrinsic'][2][1]\n",
    "    msg_info.K[8] = calib['camera_intrinsic'][2][2]\n",
    "    \n",
    "    msg_info.R[0] = 1\n",
    "    msg_info.R[3] = 1\n",
    "    msg_info.R[6] = 1\n",
    "    \n",
    "    msg_info.P[0] = msg_info.K[0]\n",
    "    msg_info.P[1] = msg_info.K[1]\n",
    "    msg_info.P[2] = msg_info.K[2]\n",
    "    msg_info.P[3] = 0\n",
    "    msg_info.P[4] = msg_info.K[3]\n",
    "    msg_info.P[5] = msg_info.K[4]\n",
    "    msg_info.P[6] = msg_info.K[5]\n",
    "    msg_info.P[7] = 0\n",
    "    msg_info.P[8] = 0\n",
    "    msg_info.P[9] = 0\n",
    "    msg_info.P[10] = 1\n",
    "    msg_info.P[11] = 0\n",
    "    return msg_info\n",
    "\n",
    "def get_lidar(sample_data, frame_id):\n",
    "    pc_filename = 'data/' + sample_data['filename']\n",
    "    pc_filesize = os.stat(pc_filename).st_size\n",
    "\n",
    "    with open(pc_filename, 'rb') as pc_file:\n",
    "        msg = PointCloud2()\n",
    "        msg.header.frame_id = frame_id\n",
    "        msg.header.stamp = get_time(sample_data)\n",
    "\n",
    "        msg.fields = [\n",
    "            PointField(name='x', offset=0, datatype=PointField.FLOAT32, count=1),\n",
    "            PointField(name='y', offset=4, datatype=PointField.FLOAT32, count=1),\n",
    "            PointField(name='z', offset=8, datatype=PointField.FLOAT32, count=1),\n",
    "            PointField(name='intensity', offset=12, datatype=PointField.FLOAT32, count=1),\n",
    "            PointField(name='ring', offset=16, datatype=PointField.FLOAT32, count=1),\n",
    "        ]\n",
    "\n",
    "        msg.is_bigendian = False\n",
    "        msg.is_dense = True\n",
    "        msg.point_step = len(msg.fields) * 4 # 4 bytes per field\n",
    "        msg.row_step = pc_filesize\n",
    "        msg.width = round(pc_filesize / msg.point_step)\n",
    "        msg.height = 1 # unordered\n",
    "        msg.data = pc_file.read()\n",
    "        return msg\n",
    "\n",
    "def get_lidar_imagemarkers(sample_lidar, sample_data, frame_id):\n",
    "    # lidar image markers in camera frame\n",
    "    points, coloring, _ = nusc.explorer.map_pointcloud_to_image(\n",
    "        pointsensor_token=sample_lidar['token'],\n",
    "        camera_token=sample_data['token'],\n",
    "        render_intensity=True)\n",
    "    points = points.transpose()\n",
    "    coloring = [turbomap(c) for c in coloring]\n",
    "\n",
    "    marker = ImageMarker()\n",
    "    marker.header.frame_id = frame_id\n",
    "    marker.header.stamp = get_time(sample_data)\n",
    "    marker.ns = 'LIDAR_TOP'\n",
    "    marker.id = 0\n",
    "    marker.type = ImageMarker.POINTS\n",
    "    marker.action = ImageMarker.ADD\n",
    "    marker.scale = 2.0\n",
    "    marker.points = [make_point2d(p) for p in points]\n",
    "    marker.outline_colors = [make_color(c) for c in coloring]\n",
    "    return marker\n",
    "\n",
    "def get_remove_imagemarkers(frame_id, ns, stamp):\n",
    "    marker = ImageMarker()\n",
    "    marker.header.frame_id = frame_id\n",
    "    marker.header.stamp = stamp\n",
    "    marker.ns = ns\n",
    "    marker.id = 0\n",
    "    marker.action = ImageMarker.REMOVE\n",
    "    return marker\n",
    "\n",
    "def write_boxes_imagemarkers(bag, anns, sample_data, frame_id, topic_ns, stamp):\n",
    "    # annotation boxes\n",
    "    collector = Collector()\n",
    "    _, boxes, camera_intrinsic = nusc.get_sample_data(sample_data['token'])\n",
    "    for box in boxes:\n",
    "        c = np.array(nusc.explorer.get_color(box.name)) / 255.0\n",
    "        box.render(collector, view=camera_intrinsic, normalize=True, colors=(c, c, c))\n",
    "\n",
    "    marker = ImageMarker()\n",
    "    marker.header.frame_id = frame_id\n",
    "    marker.header.stamp = get_time(sample_data)\n",
    "    marker.ns = 'annotations'\n",
    "    marker.id = 0\n",
    "    marker.type = ImageMarker.LINE_LIST\n",
    "    marker.action = ImageMarker.ADD\n",
    "    marker.scale = 2.0\n",
    "    marker.points = [make_point2d(p) for p in collector.points]\n",
    "    marker.outline_colors = [make_color(c) for c in collector.colors]\n",
    "\n",
    "    msg = ImageMarkerArray()\n",
    "    msg.markers = [marker]\n",
    "\n",
    "    bag.write(topic_ns + '/image_markers_annotations', msg, stamp)\n",
    "\n",
    "def write_occupancy_grid(bag, nusc_map, ego_pose, stamp):\n",
    "    translation = ego_pose['translation']\n",
    "    rotation = Quaternion(ego_pose['rotation'])\n",
    "    yaw = quaternion_yaw(rotation) / np.pi * 180\n",
    "    patch_box = (translation[0], translation[1], 32, 32)\n",
    "    canvas_size = (patch_box[2] * 10, patch_box[3] * 10)\n",
    "\n",
    "    drivable_area = nusc_map.get_map_mask(patch_box, yaw, ['drivable_area'], canvas_size)[0]\n",
    "    drivable_area = (drivable_area * 100).astype(np.int8)\n",
    "\n",
    "    msg = OccupancyGrid()\n",
    "    msg.header.frame_id = 'base_link'\n",
    "    msg.header.stamp = stamp\n",
    "    msg.info.map_load_time = stamp\n",
    "    msg.info.resolution = 0.1\n",
    "    msg.info.width = drivable_area.shape[1]\n",
    "    msg.info.height = drivable_area.shape[0]\n",
    "    msg.info.origin.position.x = -16.0\n",
    "    msg.info.origin.position.y = -16.0\n",
    "    msg.info.origin.orientation.w = 1\n",
    "    msg.data = drivable_area.flatten().tolist()\n",
    "\n",
    "    bag.write('/drivable_area', msg, stamp)\n",
    "    \n",
    "\n",
    "def get_imu_msg(imu_data):\n",
    "    msg = Imu()\n",
    "    msg.header.frame_id = 'base_link'\n",
    "    msg.header.stamp = get_utime(imu_data)\n",
    "    msg.angular_velocity.x = imu_data['rotation_rate'][0];\n",
    "    msg.angular_velocity.y = imu_data['rotation_rate'][1];\n",
    "    msg.angular_velocity.z = imu_data['rotation_rate'][2];\n",
    "\n",
    "    msg.linear_acceleration.x = imu_data['linear_accel'][0];\n",
    "    msg.linear_acceleration.y = imu_data['linear_accel'][1];\n",
    "    msg.linear_acceleration.z = imu_data['linear_accel'][2];\n",
    "\n",
    "    msg.orientation.w = imu_data['q'][0];\n",
    "    msg.orientation.x = imu_data['q'][1];\n",
    "    msg.orientation.y = imu_data['q'][2];\n",
    "    msg.orientation.z = imu_data['q'][3];\n",
    "    \n",
    "    return (msg.header.stamp, '/imu', msg)\n",
    "\n",
    "def get_odom_msg(pose_data):\n",
    "    msg = Odometry()\n",
    "    msg.header.frame_id = 'map'\n",
    "    msg.header.stamp = get_utime(pose_data)\n",
    "    msg.child_frame_id = 'base_link'\n",
    "    msg.pose.pose.position.x = pose_data['pos'][0]\n",
    "    msg.pose.pose.position.y = pose_data['pos'][1]\n",
    "    msg.pose.pose.position.z = pose_data['pos'][2]\n",
    "    msg.pose.pose.orientation.w = pose_data['orientation'][0]\n",
    "    msg.pose.pose.orientation.x = pose_data['orientation'][1]\n",
    "    msg.pose.pose.orientation.y = pose_data['orientation'][2]\n",
    "    msg.pose.pose.orientation.z = pose_data['orientation'][3]\n",
    "    msg.twist.twist.linear.x = pose_data['vel'][0]\n",
    "    msg.twist.twist.linear.y = pose_data['vel'][1]\n",
    "    msg.twist.twist.linear.z = pose_data['vel'][2]\n",
    "    msg.twist.twist.angular.x = pose_data['rotation_rate'][0]\n",
    "    msg.twist.twist.angular.y = pose_data['rotation_rate'][1]\n",
    "    msg.twist.twist.angular.z = pose_data['rotation_rate'][2]\n",
    "    \n",
    "    return (msg.header.stamp, '/odom', msg)\n",
    "\n",
    "def get_basic_can_msg(name, diag_data):\n",
    "    values = []\n",
    "    for (key, value) in diag_data.items():\n",
    "        if key != 'utime':\n",
    "            values.append(KeyValue(key=key, value=str(round(value, 4))))\n",
    "\n",
    "    msg = DiagnosticArray()\n",
    "    msg.header.stamp = get_utime(diag_data)\n",
    "    msg.status.append(DiagnosticStatus(name=name, level=0, message='OK', values=values))\n",
    "\n",
    "    return (msg.header.stamp, '/diagnostics', msg)\n",
    "\n",
    "def get_tfs(sample):\n",
    "    sample_lidar = nusc.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "    ego_pose = nusc.get('ego_pose', sample_lidar['ego_pose_token'])\n",
    "    stamp = get_time(ego_pose)\n",
    "\n",
    "    transforms = []\n",
    "\n",
    "    # create ego transform\n",
    "    ego_tf = TransformStamped()\n",
    "    ego_tf.header.frame_id = 'map'\n",
    "    ego_tf.header.stamp = stamp\n",
    "    ego_tf.child_frame_id = 'base_link'\n",
    "    ego_tf.transform = get_transform(ego_pose)\n",
    "    transforms.append(ego_tf)\n",
    "\n",
    "    for (sensor_id, sample_token) in sample['data'].items():\n",
    "        sample_data = nusc.get('sample_data', sample_token)\n",
    "\n",
    "        # create sensor transform\n",
    "        sensor_tf = TransformStamped()\n",
    "        sensor_tf.header.frame_id = 'base_link'\n",
    "        sensor_tf.header.stamp = stamp\n",
    "        sensor_tf.child_frame_id = sensor_id\n",
    "        sensor_tf.transform = get_transform(\n",
    "            nusc.get('calibrated_sensor', sample_data['calibrated_sensor_token']))\n",
    "        transforms.append(sensor_tf)\n",
    "\n",
    "    return transforms\n",
    "\n",
    "def get_tfmessage(sample):\n",
    "    # get transforms for the current sample\n",
    "    tf_array = TFMessage()\n",
    "    tf_array.transforms = get_tfs(sample)\n",
    "\n",
    "    # add transforms from the next sample to enable interpolation\n",
    "    next_sample = nusc.get('sample', sample['next']) if sample.get('next') != '' else None\n",
    "    if next_sample is not None:\n",
    "        tf_array.transforms += get_tfs(next_sample)\n",
    "\n",
    "    return tf_array\n",
    "\n",
    "def scene_bounding_box(scene, nusc_map, padding=75.0):\n",
    "    box = [np.inf, np.inf, -np.inf, -np.inf]\n",
    "    cur_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "    while cur_sample is not None:\n",
    "        sample_lidar = nusc.get('sample_data', cur_sample['data']['LIDAR_TOP'])\n",
    "        ego_pose = nusc.get('ego_pose', sample_lidar['ego_pose_token'])\n",
    "        x, y = ego_pose['translation'][:2]\n",
    "        box[0] = min(box[0], x)\n",
    "        box[1] = min(box[1], y)\n",
    "        box[2] = max(box[2], x)\n",
    "        box[3] = max(box[3], y)\n",
    "        cur_sample = nusc.get('sample', cur_sample['next']) if cur_sample.get('next') != '' else None\n",
    "    box[0] = max(box[0] - padding, 0.0)\n",
    "    box[1] = max(box[1] - padding, 0.0)\n",
    "    box[2] = min(box[2] + padding, nusc_map.canvas_edge[0]) - box[0]\n",
    "    box[3] = min(box[3] + padding, nusc_map.canvas_edge[1]) - box[1]\n",
    "    return box\n",
    "\n",
    "def get_scene_map(scene, nusc_map, bitmap, stamp):\n",
    "    x, y, w, h = scene_bounding_box(scene, nusc_map)\n",
    "    img_x = int(x * 10)\n",
    "    img_y = int(y * 10)\n",
    "    img_w = int(w * 10)\n",
    "    img_h = int(h * 10)\n",
    "    img = np.flipud(bitmap.image)[img_y:img_y+img_h, img_x:img_x+img_w]\n",
    "    img = (img * (100.0 / 255.0)).astype(np.int8)\n",
    "\n",
    "    msg = OccupancyGrid()\n",
    "    msg.header.frame_id = 'map'\n",
    "    msg.header.stamp = stamp\n",
    "    msg.info.map_load_time = stamp\n",
    "    msg.info.resolution = 0.1\n",
    "    msg.info.width = img_w\n",
    "    msg.info.height = img_h\n",
    "    msg.info.origin.position.x = x\n",
    "    msg.info.origin.position.y = y\n",
    "    msg.info.origin.orientation.w = 1\n",
    "    msg.data = img.flatten().tolist()\n",
    "\n",
    "    return msg\n",
    "\n",
    "def rectContains(rect, point):\n",
    "    a, b, c, d = rect\n",
    "    x, y = point[:2]\n",
    "    return a <= x < a + c and b <= y < b + d\n",
    "\n",
    "def get_centerline_markers(scene, nusc_map, stamp):\n",
    "    pose_lists = nusc_map.discretize_centerlines(1)\n",
    "    bbox = scene_bounding_box(scene, nusc_map)\n",
    "\n",
    "    contained_pose_lists = []\n",
    "    for pose_list in pose_lists:\n",
    "        new_pose_list = []\n",
    "        for pose in pose_list:\n",
    "            if rectContains(bbox, pose):\n",
    "                new_pose_list.append(pose)\n",
    "        if len(new_pose_list) > 0:\n",
    "            contained_pose_lists.append(new_pose_list)\n",
    "    \n",
    "    msg = MarkerArray()\n",
    "    for i, pose_list in enumerate(contained_pose_lists):\n",
    "        marker = Marker()\n",
    "        marker.header.frame_id = 'map'\n",
    "        marker.header.stamp = stamp\n",
    "        marker.ns = 'centerline'\n",
    "        marker.id = i\n",
    "        marker.type = Marker.LINE_STRIP\n",
    "        marker.action = Marker.ADD\n",
    "        marker.frame_locked = True\n",
    "        marker.scale.x = 0.1\n",
    "        marker.color.r = 51.0 / 255.0\n",
    "        marker.color.g = 160.0 / 255.0\n",
    "        marker.color.b = 44.0 / 255.0\n",
    "        marker.color.a = 1.0\n",
    "        marker.pose.orientation.w = 1.0\n",
    "        for pose in pose_list:\n",
    "            marker.points.append(Point(pose[0], pose[1], 0))\n",
    "        msg.markers.append(marker)\n",
    "\n",
    "    return msg\n",
    "\n",
    "def find_closest_lidar(lidar_start_token, stamp_nsec):\n",
    "    candidates = []\n",
    "\n",
    "    next_lidar_token = nusc.get('sample_data', lidar_start_token)['next']\n",
    "    while next_lidar_token != '':\n",
    "        lidar_data = nusc.get('sample_data', next_lidar_token)\n",
    "        if lidar_data['is_key_frame']:\n",
    "            break\n",
    "\n",
    "        dist_abs = abs(stamp_nsec - get_time(lidar_data).to_nsec())\n",
    "        candidates.append((dist_abs, lidar_data))\n",
    "        next_lidar_token = lidar_data['next']\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        return None\n",
    "\n",
    "    return min(candidates, key=lambda x: x[0])[1]\n",
    "\n",
    "\n",
    "class Collector:\n",
    "    \"\"\"\n",
    "    Emulates the Matplotlib Axes class to collect line data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.points = []\n",
    "        self.colors = []\n",
    "\n",
    "    def plot(self, xx, yy, color, linewidth):\n",
    "        x1, x2 = xx\n",
    "        y1, y2 = yy\n",
    "        self.points.append((x1, y1))\n",
    "        self.points.append((x2, y2))\n",
    "        self.colors.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scene(scene):\n",
    "    scene_name = scene['name']\n",
    "    log = nusc.get('log', scene['log_token'])\n",
    "    location = log['location']\n",
    "    print(f'Loading map \"{location}\"')\n",
    "    nusc_map = NuScenesMap(dataroot='data', map_name=location)\n",
    "    print(f'Loading bitmap \"{nusc_map.map_name}\"')\n",
    "    bitmap = BitMap(nusc_map.dataroot, nusc_map.map_name, 'basemap')\n",
    "    print(f'Loaded {bitmap.image.shape} bitmap')\n",
    "\n",
    "    cur_sample = nusc.get('sample', scene['first_sample_token'])\n",
    "\n",
    "    can_parsers = [\n",
    "        [nusc_can.get_messages(scene_name, 'ms_imu'), 0, get_imu_msg],\n",
    "        [nusc_can.get_messages(scene_name, 'pose'), 0, get_odom_msg],\n",
    "        [nusc_can.get_messages(scene_name, 'steeranglefeedback'), 0, lambda x: get_basic_can_msg('Steering Angle', x)],\n",
    "        [nusc_can.get_messages(scene_name, 'vehicle_monitor'), 0, lambda x: get_basic_can_msg('Vehicle Monitor', x)],\n",
    "        [nusc_can.get_messages(scene_name, 'zoesensors'), 0, lambda x: get_basic_can_msg('Zoe Sensors', x)],\n",
    "        [nusc_can.get_messages(scene_name, 'zoe_veh_info'), 0, lambda x: get_basic_can_msg('Zoe Vehicle Info', x)],\n",
    "    ]\n",
    "\n",
    "    bag_name = f'NuScenes-{NUSCENES_VERSION}-{scene_name}.bag'\n",
    "    bag_path = os.path.join(os.path.abspath(os.curdir), bag_name)\n",
    "    print(f'Writing to {bag_path}')\n",
    "    bag = rosbag.Bag(bag_path, 'w', compression='lz4')\n",
    "\n",
    "    stamp = get_time(nusc.get('ego_pose', nusc.get('sample_data', cur_sample['data']['LIDAR_TOP'])['ego_pose_token']))\n",
    "    map_msg = get_scene_map(scene, nusc_map, bitmap, stamp)\n",
    "    centerlines_msg = get_centerline_markers(scene, nusc_map, stamp)\n",
    "    bag.write('/map', map_msg, stamp)\n",
    "    bag.write('/semantic_map', centerlines_msg, stamp)\n",
    "    last_map_stamp = stamp\n",
    "\n",
    "    while cur_sample is not None:\n",
    "        sample_lidar = nusc.get('sample_data', cur_sample['data']['LIDAR_TOP'])\n",
    "        ego_pose = nusc.get('ego_pose', sample_lidar['ego_pose_token'])\n",
    "        stamp = get_time(ego_pose)\n",
    "\n",
    "        # write map topics every two seconds\n",
    "        if stamp - rospy.Duration(2.0) >= last_map_stamp:\n",
    "            map_msg.header.stamp = stamp\n",
    "            for marker in centerlines_msg.markers:\n",
    "                marker.header.stamp = stamp\n",
    "            bag.write('/map', map_msg, stamp)\n",
    "            bag.write('/semantic_map', centerlines_msg, stamp)\n",
    "            last_map_stamp = stamp\n",
    "\n",
    "        # write CAN messages to /pose, /odom, and /diagnostics\n",
    "        can_msg_events = []\n",
    "        for i in range(len(can_parsers)):\n",
    "            (can_msgs, index, msg_func) = can_parsers[i]\n",
    "            while index < len(can_msgs) and get_utime(can_msgs[index]) < stamp:\n",
    "                can_msg_events.append(msg_func(can_msgs[index]))\n",
    "                index += 1\n",
    "                can_parsers[i][1] = index\n",
    "        can_msg_events.sort(key = lambda x: x[0])\n",
    "        for (msg_stamp, topic, msg) in can_msg_events:\n",
    "            bag.write(topic, msg, stamp)\n",
    "\n",
    "        # publish /tf\n",
    "        tf_array = get_tfmessage(cur_sample)\n",
    "        bag.write('/tf', tf_array, stamp)\n",
    "\n",
    "        # /driveable_area occupancy grid\n",
    "        write_occupancy_grid(bag, nusc_map, ego_pose, stamp)\n",
    "\n",
    "        # iterate sensors\n",
    "        for (sensor_id, sample_token) in cur_sample['data'].items():\n",
    "            sample_data = nusc.get('sample_data', sample_token)\n",
    "            topic = '/' + sensor_id\n",
    "\n",
    "            # write the sensor data\n",
    "            if sample_data['sensor_modality'] == 'radar':\n",
    "                msg = get_radar(sample_data, sensor_id)\n",
    "                bag.write(topic, msg, stamp)\n",
    "            elif sample_data['sensor_modality'] == 'lidar':\n",
    "                msg = get_lidar(sample_data, sensor_id)\n",
    "                bag.write(topic, msg, stamp)\n",
    "            elif sample_data['sensor_modality'] == 'camera':\n",
    "                msg = get_camera(sample_data, sensor_id)\n",
    "                bag.write(topic + '/image_rect_compressed', msg, stamp)\n",
    "                msg = get_camera_info(sample_data, sensor_id)\n",
    "                bag.write(topic + '/camera_info', msg, stamp)\n",
    "\n",
    "            if sample_data['sensor_modality'] == 'camera':\n",
    "                msg = get_lidar_imagemarkers(sample_lidar, sample_data, sensor_id)\n",
    "                bag.write(topic + '/image_markers_lidar', msg, stamp)\n",
    "                write_boxes_imagemarkers(bag, cur_sample['anns'], sample_data, sensor_id, topic, stamp)\n",
    "\n",
    "        # publish /pose\n",
    "        pose_stamped = PoseStamped()\n",
    "        pose_stamped.header.frame_id = 'base_link'\n",
    "        pose_stamped.header.stamp = stamp\n",
    "        pose_stamped.pose.orientation.w = 1\n",
    "        bag.write('/pose', pose_stamped, stamp)\n",
    "\n",
    "        # publish /gps\n",
    "        coordinates = derive_latlon(location, ego_pose)\n",
    "        gps = NavSatFix()\n",
    "        gps.header.frame_id = 'base_link'\n",
    "        gps.header.stamp = stamp\n",
    "        gps.status.status = 1\n",
    "        gps.status.service = 1\n",
    "        gps.latitude = coordinates['latitude']\n",
    "        gps.longitude = coordinates['longitude']\n",
    "        gps.altitude = get_transform(ego_pose).translation.z\n",
    "        bag.write('/gps', gps, stamp)\n",
    "\n",
    "        # publish /markers/annotations\n",
    "        marker_array = MarkerArray()\n",
    "        for annotation_id in cur_sample['anns']:\n",
    "            ann = nusc.get('sample_annotation', annotation_id)\n",
    "            marker_id = int(ann['instance_token'][:4], 16)\n",
    "            c = np.array(nusc.explorer.get_color(ann['category_name'])) / 255.0\n",
    "\n",
    "            marker = Marker()\n",
    "            marker.header.frame_id = 'map'\n",
    "            marker.header.stamp = stamp\n",
    "            marker.id = marker_id\n",
    "            marker.text = ann['instance_token'][:4]\n",
    "            marker.type = Marker.CUBE\n",
    "            marker.pose = get_pose(ann)\n",
    "            marker.frame_locked = True\n",
    "            marker.scale.x = ann['size'][1]\n",
    "            marker.scale.y = ann['size'][0]\n",
    "            marker.scale.z = ann['size'][2]\n",
    "            marker.color = make_color(c, 0.5)\n",
    "            marker_array.markers.append(marker)\n",
    "        bag.write('/markers/annotations', marker_array, stamp)\n",
    "\n",
    "        # collect all sensor frames after this sample but before the next sample\n",
    "        non_keyframe_sensor_msgs = []\n",
    "        for (sensor_id, sample_token) in cur_sample['data'].items():\n",
    "            topic = '/' + sensor_id\n",
    "\n",
    "            next_sample_token = nusc.get('sample_data', sample_token)['next']\n",
    "            while next_sample_token != '':\n",
    "                next_sample_data = nusc.get('sample_data', next_sample_token)\n",
    "                # if next_sample_data['is_key_frame'] or get_time(next_sample_data).to_nsec() > next_stamp.to_nsec():\n",
    "                #     break\n",
    "                if next_sample_data['is_key_frame']:\n",
    "                    break\n",
    "\n",
    "                if next_sample_data['sensor_modality'] == 'radar':\n",
    "                    msg = get_radar(next_sample_data, sensor_id)\n",
    "                    non_keyframe_sensor_msgs.append((msg.header.stamp.to_nsec(), topic, msg))\n",
    "                elif next_sample_data['sensor_modality'] == 'lidar':\n",
    "                    msg = get_lidar(next_sample_data, sensor_id)\n",
    "                    non_keyframe_sensor_msgs.append((msg.header.stamp.to_nsec(), topic, msg))\n",
    "                elif next_sample_data['sensor_modality'] == 'camera':\n",
    "                    msg = get_camera(next_sample_data, sensor_id)\n",
    "                    camera_stamp_nsec = msg.header.stamp.to_nsec()\n",
    "                    non_keyframe_sensor_msgs.append((camera_stamp_nsec, topic + '/image_rect_compressed', msg))\n",
    "\n",
    "                    msg = get_camera_info(next_sample_data, sensor_id)\n",
    "                    non_keyframe_sensor_msgs.append((camera_stamp_nsec, topic + '/camera_info', msg))\n",
    "\n",
    "                    closest_lidar = find_closest_lidar(cur_sample['data']['LIDAR_TOP'], camera_stamp_nsec)\n",
    "                    if closest_lidar is not None:\n",
    "                        msg = get_lidar_imagemarkers(closest_lidar, next_sample_data, sensor_id)\n",
    "                        non_keyframe_sensor_msgs.append((msg.header.stamp.to_nsec(), topic + '/image_markers_lidar', msg))\n",
    "                    else:\n",
    "                        msg = get_remove_imagemarkers(sensor_id, 'LIDAR_TOP', msg.header.stamp)\n",
    "                        non_keyframe_sensor_msgs.append((msg.header.stamp.to_nsec(), topic + '/image_markers_lidar', msg))\n",
    "\n",
    "                    # Delete all image markers on non-keyframe camera images\n",
    "                    # msg = get_remove_imagemarkers(sensor_id, 'LIDAR_TOP', msg.header.stamp)\n",
    "                    # non_keyframe_sensor_msgs.append((camera_stamp_nsec, topic + '/image_markers_lidar', msg))\n",
    "                    # msg = get_remove_imagemarkers(sensor_id, 'annotations', msg.header.stamp)\n",
    "                    # non_keyframe_sensor_msgs.append((camera_stamp_nsec, topic + '/image_markers_annotations', msg))\n",
    "\n",
    "                next_sample_token = next_sample_data['next']\n",
    "\n",
    "        # sort and publish the non-keyframe sensor msgs\n",
    "        non_keyframe_sensor_msgs.sort(key=lambda x: x[0])\n",
    "        for (_, topic, msg) in non_keyframe_sensor_msgs:\n",
    "            bag.write(topic, msg, msg.header.stamp)\n",
    "\n",
    "        # move to the next sample\n",
    "        cur_sample = nusc.get('sample', cur_sample['next']) if cur_sample.get('next') != '' else None\n",
    "\n",
    "    bag.close()\n",
    "    print(f'Finished writing {bag_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_scene(nusc.scene[0])\n",
    "\n",
    "# for scene in nusc.scene:\n",
    "#     convert_scene(scene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
